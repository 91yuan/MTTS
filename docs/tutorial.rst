笔者经验文
======================================================

语音合成新手指南
======================================================

语音合成课程&资料
------------------------------------------------------

**推荐**

* `牛津大学的深度学习课程（第十章节为tts） <https://github.com/oxford-cs-deepnlp-2017/lectures>`_
* `哥伦比亚大学的tts教程 <http://www.cs.columbia.edu/~ecooper/tts/>`_
* A beginners’ guide to statistical parametric speech synthesis
    * [英文](http://www.cstr.ed.ac.uk/downloads/publications/2010/king_hmm_tutorial.pdf)
    * [中文](https://shartoo.github.io/texttospeech/)


**其他**
* [上下文相关的GMM-HMM声学模型](http://www.cnblogs.com/cherrychenlee/p/6780460.html)
* [语音产生原理与特征参数提取](http://blog.csdn.net/u010451580/article/details/51178190)
* [English tutorial for Chinese Spoken Language Processing](http://iscslp2016.org/slides.html)
* [中文语音合成基本概念](http://staff.ustc.edu.cn/~zhling/Course_SSP/slides/Chapter_13.pdf)
* [cmu_speech_slide](http://www.speech.cs.cmu.edu/15-492/slides/)


Merlin Toolkit 使用指南
------------------------------------------------------

* Merlin: An Open Source Neural Network Speech Synthesis System   
    - [英文](http://ssw9.net/papers/ssw9_PS2-13_Wu.pdf)
    - [中文](http://blog.csdn.net/lujian1989/article/details/56008786)
* `interspeech_tutorial_for_merlin(推荐！)<http://media.speech.zone/images/Interspeech2017_tutorial_Merlin_for_publication_watermarked_compressed_v2.pdf>`_
* `Getting started with the Merlin Speech Synthesis Toolkit <http://jrmeyer.github.io/merlin/2017/02/14/Installing-Merlin.html>`_
* `Merlin官方教程（正在建设中） <http://104.131.174.95/Merlin/dnn_tts/doc/build/html/>`_

其他工具使用指南
--------------------------------------------------------

 - [HTS tutorial](http://hts.sp.nitech.ac.jp/?Tutorial)  
 - [Festvox教程（利用wav 和标记数据创造label）](http://festvox.org/bsv/)  
 - [speech.zone build-your-own-dnn-voice](http://www.speech.zone/exercises/build-your-own-dnn-voice/)   


语音识别相关
--------------------------------------

 - [机器学习&数据挖掘笔记_13（用htk完成简单的孤立词识别）](http://www.cnblogs.com/tornadomeet/p/3274078.htmli) 了解语音识别的基础


语音识别新手指南
======================================================


本教程适用范围
------------------------------------------------------
面向有计算机专业基础的读者，至少熟悉Linux，掌握shell脚本语言，掌握python，目的是学习语音识别基础知识和理论，并且追踪能够使用Kaldi工具包来完成自己的项目、实验

步骤
------------------------------------------------------
1 对语音识别有粗略的认知
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
推荐：

知乎语音识别的技术原理
https://www.zhihu.com/question/20398418

语音识别技术的前世今生_王赟的知乎live的ppt
https://zhihu-live.zhimg.com/0af15bfda98f5885ffb509acd470b0fa
可以自己手动搭一个孤立词识别，孤立词语音识别跟MNIST手写字识别几乎一模一样，直接输入声音波形，输出声波所对应的孤立词类别。可以参考下面的项目
https://github.com/microic/niy/tree/master/examples/speech_commands

另一个就是使用谷歌的Tensorflow官方语音识别入门教程
这个入门教程将教会你训练一个简单的语音识别网络，能识别10个词，就像是语音识别领域的MNIST（手写数字识别数据集）。同时这个教程也附上了相应的语音指令数据集

见网址http://www.sohu.com/a/167174796_610300

2 跑一遍kaldi
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
（1）安装Kaldi
看官方主页的Readme就可以了

（2）跑一个例子
先跑kaldi/egs/yesno 简单识别两个单词，接下来是tidigits，再接下来是hkust中文识别
可参考博客 http://blog.csdn.net/snowdroptulip/article/details/78914687

hkust项目（中文电话数据集），可参考博客
http://blog.csdn.net/AMDS123/article/details/70313787

可以从跑thchs30开始，教程https://www.jianshu.com/p/22fc9906878f
理解thchs30/s5/run.sh的主要步骤http://blog.csdn.net/BBZZ2/article/details/72884979

（3）初步阅读Kaidi的官方文档


3 学习hmm-gmm
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
途径：学习htkbook，《语音识别实践》

学习kaldi的话，先从hmm-gmm入手比较好，像steps/train_delta.sh, steps/train_fmllr.sh, steps/decode.sh这些脚本都是基于hmm-gmm模型。kaldi官网上没有多少关于hmm-gmm的资料，没有hmm-gmm基础知识的初学者可能对于decision tree，alignment, lattice这些概念一头雾水。若要搞清楚这些概念，可以看语音识别另一开原工具htk的文档htk book，htk book是学习hmm-gmm很好的一部著作，将hmm-gmm从训练到解码的过程讲解的很透彻。只要知道决策树，训练/识别网络扩展，viterbi解码，EM算法，区分训练这几个概念的原理hmm-gmm也就理解透彻了。htk book对于这些都有讲解，部分内容如EM算法，区分训练需要看一些文献。htk book第二，八，十，十二，十三章需要重点看；在学习htkbook的过程中，可以结合着kaldi的脚本对照理解；比如steps/train_delta.sh中build-tree命令那部分的代码对应htk book第十章tree-based clustering, gmm-est命令那部分的代码对应htk book第八章的Parameter Re-Estimation Formulae;

4 学习神经网络
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

搞清楚hmm-gmm之后对语音识别就有了一个清晰的理解，接下来就可以上手神经网络。kaldi支持很多神经网路，如MLP, RNN, CNN, LSTM，如果对神经网路了解不多还是从MLP入手较好，MLP是神经网路中最基础的模型。
神经网路kaldi有3个工具nnet1, nnet2, nnet3，初学者可以从nnet1开始。nnet1使用的是hmm-dnn架构，相关的知识可以查阅微软俞栋2009-2013期间发表的论文。
nnet2的架构和nnet1同样是hmm-dnn架构，但是使用的是dan povey团队设计的NSGD算法，支持多线程并行训练，学习nnet2可以追dan povey从2012年之后的论文
至于nnet3，chain model,以及其他的神经网路结构(rn,cnn,lstm)的学习，

5 看论文
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
当完成我上面的说的学习内容后自然对语音识别有一个大体的认识，后面要做的就是看相关的文献。微软，dan povey，google, 多伦多大学来自这些地方的论文不断的追就行了。
最后总结，语音识别是对理论要求很高的方向，学习过程中一定要注重理论知识的学习，很多公式还是有必要自己去推导下才能有深刻的理解。

资料推荐
------------------------------------------------------
论文
多关注ICASSP，InterSpeech的论文集

文字资料
------------------------------------------------------
Kaldi的官方文档
网友总结的《kaldi的全部资料_v0.4.pdf》
以及《Chinese_doc_of_kaldi》

王赟的知乎live pdf
https://zhihu-live.zhimg.com/0af15bfda98f5885ffb509acd470b0fa

HMM-GMM部分
<htk book>: HTK Speech Recognition Toolkit
http://lasa.epfl.ch/teaching/lectures/ML_Phd/Notes/GP-GMM.pdf
此文献详细讲解了hmm-gmm训练算法的推导过程
http://www.cc.gatech.edu/~dellaert/em-paper.pdf
此文献详细讲解了EM算法的基本原理
Discriminative Training for Large Vocabulary Speech Recognition (PDF Download Available)
此文献详细讲解了区分训练的基本原理
神经网络部分:
Dan Povey
kaldi作者Dan Povey的个人主页，学习nnet2, nnet3, chain model看Povey的论文会很有帮助；

书籍
------------------------------------------------------
htkbook 《语音信号处理》《语音识别实践》《统计学习方法》《机器学习》《模式识别》

《语音识别实践》：微软研究院俞栋对HMM-DNN架构在语音识别中的相关理论讲解；内容主要是2009~2014期间学术界关于HMM-DNN架构的论文；
《模式识别》: 这本书第四章的非线性分类器作为神经网络的入门还是很合适的，理论讲解很详细；

网络课程
------------------------------------------------------

（1）ASR webpage （ASR 课程）
（2）Speech Processing: 15-492/18-492 (CMU ASR课程）

一些工具的使用方法
------------------------------------------------------

FFmpeg
http://blog.csdn.net/Allyli0022/article/details/78355248

sox
todo


常见问题与解答
------------------------------------------------------
kaldi triphone decision tree 训练生成的tree结构是怎样的？
见回答：https://www.zhihu.com/question/263969544/answer/275975955


声学基础
======================================================

此部分建议详细学习《语音信号处理》韩纪庆 清华大学出版社 一书以及 实验语音学 相关书籍，下面的内容仅仅是简要的介绍
语音信号
出处：https://zhuanlan.zhihu.com/p/27778749

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

语音信号获取
------------------------------------------------------

语音信号通过麦克风采集，经过采样和 A/D 转换后由模拟信号转变为数字信号。然后对语音的数字信号进行预加重，分帧，加窗，端点检测和滤波等处理。 预处理过后的语音信号将按照特定的特征 取方法 取出最能够表现这段语 音信号特征的参数，这些特征参数按时间序列构成了这段语音信号的特征序列。 

**采样、量化和编码**：

麦克风将声音从物理状态转化为模拟的电信号，把连续的模拟信号转化为时间上离散、但幅值上仍连续的离散模拟信号，这一过程就是采样。
通常在 PC 机上的采样频率为 16kHz，嵌入式设备上为 8kHz。

编码，就是用一组	二进制	码组来表示每一个有固定电平的量化值。然而，实际上量化是在编码过程中同时完成的，故编码过程也称为	模/数变换	，可记作A/D。

为了便于计算机计算、传输和存储，采样后的信号还要转化为能够用二进制表示的离散值，这一过程就称为 A/D 转换。保证 A/D 转换具有足够的转换精度。通常采用的方法是均匀量化和脉冲编码调制(PCM，Pulse Code Modulation)，当前语音识别中常用 16bit 量化。

**脉冲编码调制**就是把一个时间连续，取值连续的模拟信号变换成时间离散，取值离散的数字信号后在信道中传输。脉冲编码调制就是对模拟信号先抽样，再对样值幅度量化，编码的过程。

**预加重，分帧和加窗**：

高频部分在 800Hz 以上会有-6dB/倍频程的跌落，预加重的目的就是提升语音信号的高频部分，使频谱平滑。一般预加重通过一个一阶高通滤波器实现。 在对语音信号进行分析前，需要对其进行分帧，通常将语音信号的每帧长度设为 20ms，相邻两帧之间有 10ms 的重叠。为了实现分帧步骤，我们要对语音信号进行加窗操作。不同的窗口选择对语音信号分析的结果会产生影响。 通常我们选择的窗函数为汉明窗。

语音信号分析：
------------------------------------------------------
**时域分析**：

由于对信号的平方运算人为增加了高频信号和低频信号的差距，因此在某些场合可能会造成更大的误差。为了解决这个问题，最简单的方法是用短时平均幅值的变化来表示能量的变化。 短时平均过零率(ZCR，Zero Crossing Rate)是指短时间内信号通过零值的次数，具体于连续信号即其波形通过 x 轴的次数，离散信号即采样符号变化的次数。 短时过零率在一定程度上能够反映频率的高低，浊音的过零率较低，清音的过零率相对较高，因此可以用来初步分析清、浊音。短时过零率容易受到低频的干扰，通常我们在处理中还会加入门限值，即将波形穿过零点的次数改为越过门限值的次数，以此来增强抗干扰能力。 在语音信号处理中，常将短时平均能量和短时平均过零率结合起来进行语音段起始点的检测，即端点检测。当背景噪声较小时，用短时平均能量的方法比较准确，

**频域分析**：

在语音信号分析中，常用的频域分析方法有滤波器组和傅里叶变换的方法。

共振峰是一个典型的频域参数，它可以决定信号频谱的总体轮廓或谱包络(spectrum envelop)。 对于声道而言，它的共振频率不止一个，一般元音可以有3~5个共振峰。

当采用宽带带通滤波器时，频率分辨率较低，其与加窗处理中窗口较短时的处理结果相近;采用窄带带通滤波器时，频率分辨率较高，与窗口较长时的处理结果相近。 通常用一组滤波器组对语音输入信号进行滤波处理，分离出输入信号中不同中心频率的分量，再进行各种分析和处理。

通常用离散傅里叶变换代替连续傅里叶变换。但是随着技术的发展，傅里叶变换的一些局限性也渐渐体现出来:首先，傅里叶变换的时间分辨率为零，不能反映信号在时域上的信息;其次，傅里叶变换是基于信号是平稳的这个假设，而在实际生活中，很多声音信号是非平稳的;最后，傅里叶变换在整个频段内的分辨率都是相同的，不能反映信号在某一频段的某种变化。同时，将声音信号进行频率分析，计算量较大，在对实时性要求高而计算资源又受限的嵌入式设备上也是一个难题。

**语谱图**
语谱图spectrogram：横坐标表示时间，纵坐标表示频率，每个像素的灰度值大小反映相应时刻和相应频率的能量。根据带通滤波器的宽窄分为宽带语谱图和窄带语谱图。

**声学特征**：
通常我们将声学特征分为两大类，一类为基于人类发声机理的特征，另一类为基于人耳听觉感知的特征，而这两类具有代表性的特征分别是线性预测倒谱系数(LPCC，Linear Prediction Cepstrum Coefficient)和 Mel 频率倒谱系数(MFCC，Mel Frequency Cepstrum Coefficient)。 MFCC[11]特征是一种基于人类听觉感知特性的特征，模拟了人耳对不同频率的感知程度，其对中低频语音信号较敏感，对高频信息的区分度不大，因而能够从信号的中低频段 取更多语音信息。 提取一组 MFCC 特征主要有以下几个步骤: 1.首先对输入的语音信号进行预处理，得到分帧和加窗后的时域信号; 2.对时域信号进行快速傅里叶变换(FFT，Fast Fourier Transform)，得到语音信号的频率表达; 3.将得到的线性频率转换为 Mel 频率 4.在 Mel 频率轴上构造 M 个三角带通滤波器组，这 M 个三角滤波器在 Mel 频率尺度上是平均分布的。以 MFCC 为特征的语音识别系统并不会受到输入语音的音调不同而有所影响;二是降低了信息量。 5.离散余弦变换(DCT，Discrete Cosine Transform)。对每一个滤波器的输出计算其对数能量 Em ，并做 DCT 变换。

语音的产生机理与模型
参考文献：《数字语音编码技术》电子工业出版社

人的发声器官由4个部分组成：肺、喉、声道和嘴。嘴的作用是完成声道的气流向外辐射，嘴的张开形状会影响语音频谱的形状，但是其作用较之声道较弱，因此常将发音器官分成3个部分：肺、喉和声道。

肺：动力源，将气流送至喉部

喉：将来自肺部的气流调制为周期脉冲或类似随机噪声的激励声源

声道：声道包括口腔、鼻腔和咽腔，它们对声源的频谱进行整形从而产生不同音色的声音。

术语解析
------------------------------------------------------

调制：信号调制是使一种波形的某些特性按另一种波形或信号而变化的过程或处理方法。按调制信号的形式可分为模拟调制和数字调制。用模拟信号调制称为模拟调制；用数据或数字信号调制称为数字调制。

激励声源：“ 激励”与“响应”是“信号与系统”学科的两个基本概念。“激励”又称为“激励源”，是施加于系统的外部原因，而“响应”则是系统在这个外部原因作用下引起的结果。激励源即激励端口，是一种允许能量流入和流出结构的边界条件。这里将激励声源当做声音产生器就好。

**浊音和清音**

浊音时声带振动，清音时声带不振动

说话时，气流会周期性地通过声带（声带因为气流通过时产生的压力大小变化会不断地周期性闭合），从而产生周期性的脉冲气流通过。这气流的频率就称之为基音频率F0。

.. figure:: ../img/f0.jpg
   :width: 32

   图：f0

语音流中，音节(syllable)是由音素(phoneme)结合而成的最小单位，同时也是发声的最小单位。一个音节由元音(Vowel)和辅音(Consonant)构成。在汉语普通话中，每个音节都是由“辅音-元音”构成的（也有零辅音的情况），这种结构称之为"C-V"结构，其他语系中有不同的结构如“C-V-C”，汉语中辅音也称之为声母，元音称之为韵母。

单独发声的一个音节或是语音流中的任何一个音节都有可能由9个部分组成，如图所示

.. figure:: ../img/syllable.jpg
   :width: 32

   图：音节发音结构


汉语普通话中有四种声调，分别是阴平、阳平、上声和去声，或成为一二三四声。声调在普通话中承担着重要的构字辨意作用。不同声调是通过基音频率的变化轨迹（也称之为声调曲线）来区分的，从一个韵母的起始端开始，到韵母的终止端结束，图中给出了单独说一个音节时4种声调的典型曲线。

.. figure:: ../img/tone.jpg
   :width: 32

   图：声调曲线






